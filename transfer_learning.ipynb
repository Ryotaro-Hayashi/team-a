{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalgo-intern/team-a/blob/master/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o3ggDXWrdHG",
        "colab_type": "code",
        "outputId": "d650d544-c4a7-4aae-95a2-5f7d828788b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8KO-fwWs28Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1WxOK8oyxZ_jJkaJ4zLa_nbfnmDijh0M9'})\n",
        "\n",
        "downloaded.GetContentFile('train_p_nothuman.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfhHGpmwtRX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1oiDVeU8A14ukiD247w8G_xueVhwiy2uK'})\n",
        "\n",
        "downloaded.GetContentFile('validation_p_nothuman.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykJbu-SQtdmX",
        "colab_type": "code",
        "outputId": "af6641bf-8139-4b8e-fbd0-e3c6dc1210b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip train_p_nothuman.zip\n",
        "!unzip validation_p_nothuman.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train_p_nothuman.zip\n",
            "   creating: train/chimpanzee/\n",
            "  inflating: train/chimpanzee/10037667855.jpg  \n",
            "  inflating: train/chimpanzee/10059377785.jpg  \n",
            "  inflating: train/chimpanzee/10803455094.jpg  \n",
            "  inflating: train/chimpanzee/11581412744.jpg  \n",
            "  inflating: train/chimpanzee/11950809213.jpg  \n",
            "  inflating: train/chimpanzee/12184235744.jpg  \n",
            "  inflating: train/chimpanzee/14974695853.jpg  \n",
            "  inflating: train/chimpanzee/14993392243.jpg  \n",
            "  inflating: train/chimpanzee/15039218068.jpg  \n",
            "  inflating: train/chimpanzee/15165394638.jpg  \n",
            "  inflating: train/chimpanzee/15276624803.jpg  \n",
            "  inflating: train/chimpanzee/15610867861.jpg  \n",
            "  inflating: train/chimpanzee/15618200812.jpg  \n",
            "  inflating: train/chimpanzee/15657269754.jpg  \n",
            "  inflating: train/chimpanzee/15896275615.jpg  \n",
            "  inflating: train/chimpanzee/16115811169.jpg  \n",
            "  inflating: train/chimpanzee/16277952091.jpg  \n",
            "  inflating: train/chimpanzee/16501300762.jpg  \n",
            "  inflating: train/chimpanzee/16624083417.jpg  \n",
            "  inflating: train/chimpanzee/166992783.jpg  \n",
            "  inflating: train/chimpanzee/167328694.jpg  \n",
            "  inflating: train/chimpanzee/167328770.jpg  \n",
            "  inflating: train/chimpanzee/22698302113.jpg  \n",
            "  inflating: train/chimpanzee/23037668675.jpg  \n",
            "  inflating: train/chimpanzee/23048873991.jpg  \n",
            "  inflating: train/chimpanzee/23521829324.jpg  \n",
            "  inflating: train/chimpanzee/25739933352.jpg  \n",
            "  inflating: train/chimpanzee/2654309938.jpg  \n",
            "  inflating: train/chimpanzee/27027802446.jpg  \n",
            "  inflating: train/chimpanzee/27782497597.jpg  \n",
            "  inflating: train/chimpanzee/28922201883.jpg  \n",
            "  inflating: train/chimpanzee/2931872877.jpg  \n",
            "  inflating: train/chimpanzee/30921414737.jpg  \n",
            "  inflating: train/chimpanzee/3105152541.jpg  \n",
            "  inflating: train/chimpanzee/31668083635.jpg  \n",
            "  inflating: train/chimpanzee/32061320867.jpg  \n",
            "  inflating: train/chimpanzee/32345189407.jpg  \n",
            "  inflating: train/chimpanzee/32382328807.jpg  \n",
            "  inflating: train/chimpanzee/3253635631.jpg  \n",
            "  inflating: train/chimpanzee/32717648106.jpg  \n",
            "  inflating: train/chimpanzee/32758614457.jpg  \n",
            "  inflating: train/chimpanzee/33502127540.jpg  \n",
            "  inflating: train/chimpanzee/3380419269.jpg  \n",
            "  inflating: train/chimpanzee/34043902782.jpg  \n",
            "  inflating: train/chimpanzee/34148696046.jpg  \n",
            "  inflating: train/chimpanzee/34765616100.jpg  \n",
            "  inflating: train/chimpanzee/3507560023.jpg  \n",
            "  inflating: train/chimpanzee/35353594152.jpg  \n",
            "  inflating: train/chimpanzee/35829807564.jpg  \n",
            "  inflating: train/chimpanzee/37048674136.jpg  \n",
            "  inflating: train/chimpanzee/3743172664.jpg  \n",
            "  inflating: train/chimpanzee/41613475782.jpg  \n",
            "  inflating: train/chimpanzee/4180375982.jpg  \n",
            "  inflating: train/chimpanzee/45648509644.jpg  \n",
            "  inflating: train/chimpanzee/4639443982.jpg  \n",
            "  inflating: train/chimpanzee/46573276092.jpg  \n",
            "  inflating: train/chimpanzee/47428060602.jpg  \n",
            "  inflating: train/chimpanzee/47523167171.jpg  \n",
            "  inflating: train/chimpanzee/47527792732.jpg  \n",
            "  inflating: train/chimpanzee/4807160797.jpg  \n",
            "  inflating: train/chimpanzee/5514314502.jpg  \n",
            "  inflating: train/chimpanzee/5519511070.jpg  \n",
            "  inflating: train/chimpanzee/5528498993.jpg  \n",
            "  inflating: train/chimpanzee/5612164542.jpg  \n",
            "  inflating: train/chimpanzee/5625060461.jpg  \n",
            "  inflating: train/chimpanzee/5936969040.jpg  \n",
            "  inflating: train/chimpanzee/6148356989.jpg  \n",
            "  inflating: train/chimpanzee/6148913840.jpg  \n",
            "  inflating: train/chimpanzee/6263436793.jpg  \n",
            "  inflating: train/chimpanzee/7101027279.jpg  \n",
            "  inflating: train/chimpanzee/7256564776.jpg  \n",
            "  inflating: train/chimpanzee/7760320216.jpg  \n",
            "  inflating: train/chimpanzee/7763711272.jpg  \n",
            "  inflating: train/chimpanzee/7841322394.jpg  \n",
            "  inflating: train/chimpanzee/7972546400.jpg  \n",
            "  inflating: train/chimpanzee/8032341125.jpg  \n",
            "  inflating: train/chimpanzee/8032343081.jpg  \n",
            "  inflating: train/chimpanzee/8059232711.jpg  \n",
            "  inflating: train/chimpanzee/8085053289.jpg  \n",
            "  inflating: train/chimpanzee/8113179917.jpg  \n",
            "  inflating: train/chimpanzee/8198082007.jpg  \n",
            "  inflating: train/chimpanzee/8201497608.jpg  \n",
            "  inflating: train/chimpanzee/8234610687.jpg  \n",
            "  inflating: train/chimpanzee/8234612481.jpg  \n",
            "  inflating: train/chimpanzee/8238235389.jpg  \n",
            "  inflating: train/chimpanzee/8267735672.jpg  \n",
            "  inflating: train/chimpanzee/8416828546.jpg  \n",
            "  inflating: train/chimpanzee/8417816542.jpg  \n",
            "  inflating: train/chimpanzee/8469021530.jpg  \n",
            "  inflating: train/chimpanzee/8469022594.jpg  \n",
            "  inflating: train/chimpanzee/8928335627.jpg  \n",
            "  inflating: train/chimpanzee/9342924159.jpg  \n",
            "  inflating: train/chimpanzee/9365953398.jpg  \n",
            "  inflating: train/chimpanzee/9685648951.jpg  \n",
            "  inflating: train/chimpanzee/9733518212.jpg  \n",
            "  inflating: train/chimpanzee/9847571584.jpg  \n",
            "   creating: train/gorilla/\n",
            "  inflating: train/gorilla/10057946.jpg  \n",
            "  inflating: train/gorilla/10070038356.jpg  \n",
            "  inflating: train/gorilla/10361564863.jpg  \n",
            "  inflating: train/gorilla/1055053898.jpg  \n",
            "  inflating: train/gorilla/10604947664.jpg  \n",
            "  inflating: train/gorilla/11416446263.jpg  \n",
            "  inflating: train/gorilla/11530487486.jpg  \n",
            "  inflating: train/gorilla/1383495361.jpg  \n",
            "  inflating: train/gorilla/13883344243.jpg  \n",
            "  inflating: train/gorilla/1393544284.jpg  \n",
            "  inflating: train/gorilla/141641384.jpg  \n",
            "  inflating: train/gorilla/14255962274.jpg  \n",
            "  inflating: train/gorilla/14259694395.jpg  \n",
            "  inflating: train/gorilla/14829448176.jpg  \n",
            "  inflating: train/gorilla/14944416951.jpg  \n",
            "  inflating: train/gorilla/15375819139.jpg  \n",
            "  inflating: train/gorilla/15562627758.jpg  \n",
            "  inflating: train/gorilla/15619272140.jpg  \n",
            "  inflating: train/gorilla/15841018256.jpg  \n",
            "  inflating: train/gorilla/16018693155.jpg  \n",
            "  inflating: train/gorilla/17073877127.jpg  \n",
            "  inflating: train/gorilla/173320397.jpg  \n",
            "  inflating: train/gorilla/174888866.jpg  \n",
            "  inflating: train/gorilla/17721052099.jpg  \n",
            "  inflating: train/gorilla/2078180122.jpg  \n",
            "  inflating: train/gorilla/2166595014.jpg  \n",
            "  inflating: train/gorilla/2243270762.jpg  \n",
            "  inflating: train/gorilla/22459966312.jpg  \n",
            "  inflating: train/gorilla/22484363941.jpg  \n",
            "  inflating: train/gorilla/2506576884.jpg  \n",
            "  inflating: train/gorilla/2623796462.jpg  \n",
            "  inflating: train/gorilla/2740685641.jpg  \n",
            "  inflating: train/gorilla/286459056.jpg  \n",
            "  inflating: train/gorilla/2914008619.jpg  \n",
            "  inflating: train/gorilla/3187156650.jpg  \n",
            "  inflating: train/gorilla/33265258652.jpg  \n",
            "  inflating: train/gorilla/35217956065.jpg  \n",
            "  inflating: train/gorilla/3545887001.jpg  \n",
            "  inflating: train/gorilla/35474500030.jpg  \n",
            "  inflating: train/gorilla/3551807265.jpg  \n",
            "  inflating: train/gorilla/35951865445.jpg  \n",
            "  inflating: train/gorilla/36566932610.jpg  \n",
            "  inflating: train/gorilla/3735057699.jpg  \n",
            "  inflating: train/gorilla/3785306855.jpg  \n",
            "  inflating: train/gorilla/3821765774.jpg  \n",
            "  inflating: train/gorilla/3827465833.jpg  \n",
            "  inflating: train/gorilla/3828268896.jpg  \n",
            "  inflating: train/gorilla/3875111845.jpg  \n",
            "  inflating: train/gorilla/38901448924.jpg  \n",
            "  inflating: train/gorilla/402529346.jpg  \n",
            "  inflating: train/gorilla/411233537.jpg  \n",
            "  inflating: train/gorilla/4287301929.jpg  \n",
            "  inflating: train/gorilla/44002050980.jpg  \n",
            "  inflating: train/gorilla/441665738.jpg  \n",
            "  inflating: train/gorilla/4835730140.jpg  \n",
            "  inflating: train/gorilla/4928777966.jpg  \n",
            "  inflating: train/gorilla/4939266727.jpg  \n",
            "  inflating: train/gorilla/498556593.jpg  \n",
            "  inflating: train/gorilla/5132533789.jpg  \n",
            "  inflating: train/gorilla/5226854274.jpg  \n",
            "  inflating: train/gorilla/54997969.jpg  \n",
            "  inflating: train/gorilla/5552163420.jpg  \n",
            "  inflating: train/gorilla/5602558885.jpg  \n",
            "  inflating: train/gorilla/5637804447.jpg  \n",
            "  inflating: train/gorilla/5886958428.jpg  \n",
            "  inflating: train/gorilla/5939913542.jpg  \n",
            "  inflating: train/gorilla/6018511838.jpg  \n",
            "  inflating: train/gorilla/6078118437.jpg  \n",
            "  inflating: train/gorilla/6198637891.jpg  \n",
            "  inflating: train/gorilla/6431097329.jpg  \n",
            "  inflating: train/gorilla/6434731461.jpg  \n",
            "  inflating: train/gorilla/6434732597.jpg  \n",
            "  inflating: train/gorilla/6454564819.jpg  \n",
            "  inflating: train/gorilla/65995173.jpg  \n",
            "  inflating: train/gorilla/6845464192.jpg  \n",
            "  inflating: train/gorilla/7215675976.jpg  \n",
            "  inflating: train/gorilla/7569138132.jpg  \n",
            "  inflating: train/gorilla/7790472230.jpg  \n",
            "  inflating: train/gorilla/7810300764.jpg  \n",
            "  inflating: train/gorilla/7858533006.jpg  \n",
            "  inflating: train/gorilla/8000097050.jpg  \n",
            "  inflating: train/gorilla/8074934854.jpg  \n",
            "  inflating: train/gorilla/812103234.jpg  \n",
            "  inflating: train/gorilla/8187598378.jpg  \n",
            "  inflating: train/gorilla/8198958121.jpg  \n",
            "  inflating: train/gorilla/8234487063.jpg  \n",
            "  inflating: train/gorilla/8556091250.jpg  \n",
            "  inflating: train/gorilla/8628658275.jpg  \n",
            "  inflating: train/gorilla/8656381727.jpg  \n",
            "  inflating: train/gorilla/8730404593.jpg  \n",
            "  inflating: train/gorilla/8731525850.jpg  \n",
            "  inflating: train/gorilla/8989076090.jpg  \n",
            "  inflating: train/gorilla/9103117354.jpg  \n",
            "  inflating: train/gorilla/9232320238.jpg  \n",
            "  inflating: train/gorilla/9261815510.jpg  \n",
            "  inflating: train/gorilla/9773241406.jpg  \n",
            "   creating: train/monkey/\n",
            "  inflating: train/monkey/10666178983.jpg  \n",
            "  inflating: train/monkey/11428986973.jpg  \n",
            "  inflating: train/monkey/11512536214.jpg  \n",
            "  inflating: train/monkey/11859490534.jpg  \n",
            "  inflating: train/monkey/11859584445.jpg  \n",
            "  inflating: train/monkey/12701577405.jpg  \n",
            "  inflating: train/monkey/12712968864.jpg  \n",
            "  inflating: train/monkey/13720802034.jpg  \n",
            "  inflating: train/monkey/15010678181.jpg  \n",
            "  inflating: train/monkey/1525951623.jpg  \n",
            "  inflating: train/monkey/1525961549.jpg  \n",
            "  inflating: train/monkey/1526016605.jpg  \n",
            "  inflating: train/monkey/15280942937.jpg  \n",
            "  inflating: train/monkey/15305672090.jpg  \n",
            "  inflating: train/monkey/15525739132.jpg  \n",
            "  inflating: train/monkey/16195146430.jpg  \n",
            "  inflating: train/monkey/16196632567.jpg  \n",
            "  inflating: train/monkey/16381601552.jpg  \n",
            "  inflating: train/monkey/16381652512.jpg  \n",
            "  inflating: train/monkey/16382542775.jpg  \n",
            "  inflating: train/monkey/16386739251.jpg  \n",
            "  inflating: train/monkey/16482348836.jpg  \n",
            "  inflating: train/monkey/16493734726.jpg  \n",
            "  inflating: train/monkey/16601946122.jpg  \n",
            "  inflating: train/monkey/16894894878.jpg  \n",
            "  inflating: train/monkey/20553817220.jpg  \n",
            "  inflating: train/monkey/21985312253.jpg  \n",
            "  inflating: train/monkey/2515105676.jpg  \n",
            "  inflating: train/monkey/25854947667.jpg  \n",
            "  inflating: train/monkey/25875272067.jpg  \n",
            "  inflating: train/monkey/26142438332.jpg  \n",
            "  inflating: train/monkey/26245171291.jpg  \n",
            "  inflating: train/monkey/26654140151.jpg  \n",
            "  inflating: train/monkey/26730528160.jpg  \n",
            "  inflating: train/monkey/26875257508.jpg  \n",
            "  inflating: train/monkey/30593124587.jpg  \n",
            "  inflating: train/monkey/31310339227.jpg  \n",
            "  inflating: train/monkey/32124789945.jpg  \n",
            "  inflating: train/monkey/32635614387.jpg  \n",
            "  inflating: train/monkey/32793576754.jpg  \n",
            "  inflating: train/monkey/33385845048.jpg  \n",
            "  inflating: train/monkey/33594225078.jpg  \n",
            "  inflating: train/monkey/34583518196.jpg  \n",
            "  inflating: train/monkey/34995896873.jpg  \n",
            "  inflating: train/monkey/35015944770.jpg  \n",
            "  inflating: train/monkey/3607050549.jpg  \n",
            "  inflating: train/monkey/37316164841.jpg  \n",
            "  inflating: train/monkey/37617231652.jpg  \n",
            "  inflating: train/monkey/37626868406.jpg  \n",
            "  inflating: train/monkey/37646228952.jpg  \n",
            "  inflating: train/monkey/37774148741.jpg  \n",
            "  inflating: train/monkey/38045595966.jpg  \n",
            "  inflating: train/monkey/38098247721.jpg  \n",
            "  inflating: train/monkey/38141515156.jpg  \n",
            "  inflating: train/monkey/38723977551.jpg  \n",
            "  inflating: train/monkey/41396695604.jpg  \n",
            "  inflating: train/monkey/41396696114.jpg  \n",
            "  inflating: train/monkey/44115312230.jpg  \n",
            "  inflating: train/monkey/4414109489.jpg  \n",
            "  inflating: train/monkey/45533993401.jpg  \n",
            "  inflating: train/monkey/4588552982.jpg  \n",
            "  inflating: train/monkey/46625849995.jpg  \n",
            "  inflating: train/monkey/46662537495.jpg  \n",
            "  inflating: train/monkey/47242626311.jpg  \n",
            "  inflating: train/monkey/47672244592.jpg  \n",
            "  inflating: train/monkey/5145178942.jpg  \n",
            "  inflating: train/monkey/5339114099.jpg  \n",
            "  inflating: train/monkey/5446512365.jpg  \n",
            "  inflating: train/monkey/5746316179.jpg  \n",
            "  inflating: train/monkey/5896303640.jpg  \n",
            "  inflating: train/monkey/5896347334.jpg  \n",
            "  inflating: train/monkey/5917187605.jpg  \n",
            "  inflating: train/monkey/5959360319.jpg  \n",
            "  inflating: train/monkey/6128974945.jpg  \n",
            "  inflating: train/monkey/6797033503.jpg  \n",
            "  inflating: train/monkey/6840052447.jpg  \n",
            "  inflating: train/monkey/6840065115.jpg  \n",
            "  inflating: train/monkey/7837797008.jpg  \n",
            "  inflating: train/monkey/8289735445.jpg  \n",
            "  inflating: train/monkey/8417386916.jpg  \n",
            "  inflating: train/monkey/8417531279.jpg  \n",
            "  inflating: train/monkey/8417541225.jpg  \n",
            "  inflating: train/monkey/8520760769.jpg  \n",
            "  inflating: train/monkey/8521690792.jpg  \n",
            "  inflating: train/monkey/8521890078.jpg  \n",
            "  inflating: train/monkey/8522153714.jpg  \n",
            "  inflating: train/monkey/8522172168.jpg  \n",
            "  inflating: train/monkey/c2059851232.jpg  \n",
            "  inflating: train/monkey/c2555916771.jpg  \n",
            "  inflating: train/monkey/c3066431853.jpg  \n",
            "  inflating: train/monkey/c3226155812.jpg  \n",
            "  inflating: train/monkey/c3607050735.jpg  \n",
            "  inflating: train/monkey/c3607055035.jpg  \n",
            "  inflating: train/monkey/c3688241054.jpg  \n",
            "  inflating: train/monkey/c3838554605.jpg  \n",
            "  inflating: train/monkey/c4048306554.jpg  \n",
            "Archive:  validation_p_nothuman.zip\n",
            "   creating: validation/chimpanzee/\n",
            "  inflating: validation/chimpanzee/11950809233.jpg  \n",
            "  inflating: validation/chimpanzee/11950809253.jpg  \n",
            "  inflating: validation/chimpanzee/11966528644.jpg  \n",
            "  inflating: validation/chimpanzee/14916048166.jpg  \n",
            "  inflating: validation/chimpanzee/15924817017.jpg  \n",
            "  inflating: validation/chimpanzee/16197859124.jpg  \n",
            "  inflating: validation/chimpanzee/25955172143.jpg  \n",
            "  inflating: validation/chimpanzee/26457074493.jpg  \n",
            "  inflating: validation/chimpanzee/3017601544.jpg  \n",
            "  inflating: validation/chimpanzee/32504606377.jpg  \n",
            "  inflating: validation/chimpanzee/3380377939.jpg  \n",
            "  inflating: validation/chimpanzee/36074179502.jpg  \n",
            "  inflating: validation/chimpanzee/45711151045.jpg  \n",
            "  inflating: validation/chimpanzee/47548610291.jpg  \n",
            "  inflating: validation/chimpanzee/5216632993.jpg  \n",
            "  inflating: validation/chimpanzee/5930298589.jpg  \n",
            "  inflating: validation/chimpanzee/6263454725.jpg  \n",
            "  inflating: validation/chimpanzee/6822938730.jpg  \n",
            "  inflating: validation/chimpanzee/7256595984.jpg  \n",
            "  inflating: validation/chimpanzee/7692428548.jpg  \n",
            "  inflating: validation/chimpanzee/8287741023.jpg  \n",
            "  inflating: validation/chimpanzee/8483604744.jpg  \n",
            "  inflating: validation/chimpanzee/8551454383.jpg  \n",
            "  inflating: validation/chimpanzee/9678800009.jpg  \n",
            "   creating: validation/gorilla/\n",
            "  inflating: validation/gorilla/12261123623.jpg  \n",
            "  inflating: validation/gorilla/15461447313.jpg  \n",
            "  inflating: validation/gorilla/16766126650.jpg  \n",
            "  inflating: validation/gorilla/17908414745.jpg  \n",
            "  inflating: validation/gorilla/23683068319.jpg  \n",
            "  inflating: validation/gorilla/2401698195.jpg  \n",
            "  inflating: validation/gorilla/3159666520.jpg  \n",
            "  inflating: validation/gorilla/3449005318.jpg  \n",
            "  inflating: validation/gorilla/34826784052.jpg  \n",
            "  inflating: validation/gorilla/3676397341.jpg  \n",
            "  inflating: validation/gorilla/5300107311.jpg  \n",
            "  inflating: validation/gorilla/5561802113.jpg  \n",
            "  inflating: validation/gorilla/6040544805.jpg  \n",
            "  inflating: validation/gorilla/6050872610.jpg  \n",
            "  inflating: validation/gorilla/6065859638.jpg  \n",
            "  inflating: validation/gorilla/61013344.jpg  \n",
            "  inflating: validation/gorilla/6214153825.jpg  \n",
            "  inflating: validation/gorilla/6292204763.jpg  \n",
            "  inflating: validation/gorilla/7229319628.jpg  \n",
            "  inflating: validation/gorilla/7467631380.jpg  \n",
            "  inflating: validation/gorilla/8730397705.jpg  \n",
            "  inflating: validation/gorilla/8730399665.jpg  \n",
            "  inflating: validation/gorilla/9116906710.jpg  \n",
            "  inflating: validation/gorilla/9278621744.jpg  \n",
            "   creating: validation/monkey/\n",
            "  inflating: validation/monkey/11859448524.jpg  \n",
            "  inflating: validation/monkey/15599735722.jpg  \n",
            "  inflating: validation/monkey/15949680656.jpg  \n",
            "  inflating: validation/monkey/16422882031.jpg  \n",
            "  inflating: validation/monkey/16447467672.jpg  \n",
            "  inflating: validation/monkey/23617354500.jpg  \n",
            "  inflating: validation/monkey/24284166389.jpg  \n",
            "  inflating: validation/monkey/24337817686.jpg  \n",
            "  inflating: validation/monkey/25760501267.jpg  \n",
            "  inflating: validation/monkey/32029228865.jpg  \n",
            "  inflating: validation/monkey/3225288757.jpg  \n",
            "  inflating: validation/monkey/33456044743.jpg  \n",
            "  inflating: validation/monkey/36965634384.jpg  \n",
            "  inflating: validation/monkey/37350814524.jpg  \n",
            "  inflating: validation/monkey/4247242182.jpg  \n",
            "  inflating: validation/monkey/4247243970.jpg  \n",
            "  inflating: validation/monkey/43204823565.jpg  \n",
            "  inflating: validation/monkey/5480840802.jpg  \n",
            "  inflating: validation/monkey/5488946019.jpg  \n",
            "  inflating: validation/monkey/5751831980.jpg  \n",
            "  inflating: validation/monkey/5959922042.jpg  \n",
            "  inflating: validation/monkey/6840048033.jpg  \n",
            "  inflating: validation/monkey/6840049711.jpg  \n",
            "  inflating: validation/monkey/c1525961549.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5i4j_YZtlvG",
        "colab_type": "code",
        "outputId": "5e61c33e-3b29-4f35-ad3e-97ac691e60b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense,Input,GlobalMaxPooling2D,Dropout\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "N_CATEGORIES = 3\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "NUM_TRAINING = 288\n",
        "NUM_VALIDATION = 72\n",
        "\n",
        "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "base_model = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(.25)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "\n",
        "predictions = Dense(N_CATEGORIES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers[:13]:\n",
        "   layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=SGD(lr=1e-4, momentum=0.9), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "json_string=model.to_json()\n",
        "open(\"model\"+'.json','w').write(json_string)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        "   shear_range=0,\n",
        "   zoom_range=0.1,\n",
        "   horizontal_flip=True,\n",
        "   rotation_range=0)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "   rescale=1.0 / 255,\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "   'train',\n",
        "   target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "   batch_size=BATCH_SIZE,\n",
        "   class_mode='categorical',\n",
        "   shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "   'validation',\n",
        "   target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "   batch_size=BATCH_SIZE,\n",
        "   class_mode='categorical',\n",
        "   shuffle=True\n",
        ")\n",
        "\n",
        "hist = model.fit_generator(train_generator,\n",
        "   steps_per_epoch=NUM_TRAINING//BATCH_SIZE,\n",
        "   epochs=80,\n",
        "   verbose=1,\n",
        "   validation_data=validation_generator,\n",
        "   validation_steps=NUM_VALIDATION//BATCH_SIZE,\n",
        "   )\n",
        "\n",
        "model.save('ape.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 08:17:10.886590 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0827 08:17:10.901819 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0827 08:17:10.905400 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0827 08:17:10.935801 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0827 08:17:11.290105 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0827 08:17:11.293539 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0827 08:17:12.119955 140453618739072 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0827 08:17:12.180595 140453618739072 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 19,440,451\n",
            "Trainable params: 14,164,995\n",
            "Non-trainable params: 5,275,456\n",
            "_________________________________________________________________\n",
            "Found 288 images belonging to 3 classes.\n",
            "Found 72 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0827 08:17:12.534100 140453618739072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "36/36 [==============================] - 10s 276ms/step - loss: 1.0948 - acc: 0.3681 - val_loss: 1.0415 - val_acc: 0.4861\n",
            "Epoch 2/80\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 1.0094 - acc: 0.5451 - val_loss: 0.9388 - val_acc: 0.6389\n",
            "Epoch 3/80\n",
            "36/36 [==============================] - 7s 181ms/step - loss: 0.8826 - acc: 0.6597 - val_loss: 0.8445 - val_acc: 0.7083\n",
            "Epoch 4/80\n",
            "36/36 [==============================] - 6s 180ms/step - loss: 0.7473 - acc: 0.7431 - val_loss: 0.7390 - val_acc: 0.7361\n",
            "Epoch 5/80\n",
            "36/36 [==============================] - 7s 181ms/step - loss: 0.6298 - acc: 0.8090 - val_loss: 0.6578 - val_acc: 0.7083\n",
            "Epoch 6/80\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.4864 - acc: 0.8646 - val_loss: 0.5247 - val_acc: 0.8056\n",
            "Epoch 7/80\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.3752 - acc: 0.8958 - val_loss: 0.4479 - val_acc: 0.8333\n",
            "Epoch 8/80\n",
            "36/36 [==============================] - 7s 182ms/step - loss: 0.3022 - acc: 0.9167 - val_loss: 0.3660 - val_acc: 0.8472\n",
            "Epoch 9/80\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.2283 - acc: 0.9410 - val_loss: 0.3810 - val_acc: 0.8333\n",
            "Epoch 10/80\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.1689 - acc: 0.9583 - val_loss: 0.2575 - val_acc: 0.9306\n",
            "Epoch 11/80\n",
            "36/36 [==============================] - 7s 183ms/step - loss: 0.1309 - acc: 0.9722 - val_loss: 0.2356 - val_acc: 0.8889\n",
            "Epoch 12/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.1212 - acc: 0.9757 - val_loss: 0.2243 - val_acc: 0.9306\n",
            "Epoch 13/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.1000 - acc: 0.9757 - val_loss: 0.2286 - val_acc: 0.9306\n",
            "Epoch 14/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0834 - acc: 0.9826 - val_loss: 0.1886 - val_acc: 0.9444\n",
            "Epoch 15/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0555 - acc: 0.9896 - val_loss: 0.2077 - val_acc: 0.9167\n",
            "Epoch 16/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0565 - acc: 0.9931 - val_loss: 0.2082 - val_acc: 0.9167\n",
            "Epoch 17/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0473 - acc: 0.9896 - val_loss: 0.1855 - val_acc: 0.9028\n",
            "Epoch 18/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0429 - acc: 0.9931 - val_loss: 0.1657 - val_acc: 0.9167\n",
            "Epoch 19/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.9444\n",
            "Epoch 20/80\n",
            "36/36 [==============================] - 7s 186ms/step - loss: 0.0325 - acc: 0.9931 - val_loss: 0.1625 - val_acc: 0.9306\n",
            "Epoch 21/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0259 - acc: 0.9931 - val_loss: 0.1658 - val_acc: 0.9444\n",
            "Epoch 22/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0196 - acc: 0.9965 - val_loss: 0.1817 - val_acc: 0.9444\n",
            "Epoch 23/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.9444\n",
            "Epoch 24/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0184 - acc: 0.9965 - val_loss: 0.1756 - val_acc: 0.9444\n",
            "Epoch 25/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 0.9444\n",
            "Epoch 26/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9444\n",
            "Epoch 27/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9444\n",
            "Epoch 28/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9444\n",
            "Epoch 29/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.1711 - val_acc: 0.9444\n",
            "Epoch 30/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.2117 - val_acc: 0.9444\n",
            "Epoch 31/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.9444\n",
            "Epoch 32/80\n",
            "36/36 [==============================] - 7s 186ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1444 - val_acc: 0.9444\n",
            "Epoch 33/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9444\n",
            "Epoch 34/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1890 - val_acc: 0.9444\n",
            "Epoch 35/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9444\n",
            "Epoch 36/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0099 - acc: 0.9965 - val_loss: 0.1475 - val_acc: 0.9444\n",
            "Epoch 37/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1445 - val_acc: 0.9444\n",
            "Epoch 38/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9444\n",
            "Epoch 39/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 0.9444\n",
            "Epoch 40/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9444\n",
            "Epoch 41/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9444\n",
            "Epoch 42/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9444\n",
            "Epoch 43/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 0.9444\n",
            "Epoch 44/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9444\n",
            "Epoch 45/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9444\n",
            "Epoch 46/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1995 - val_acc: 0.9444\n",
            "Epoch 47/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1984 - val_acc: 0.9444\n",
            "Epoch 48/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9444\n",
            "Epoch 49/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1674 - val_acc: 0.9444\n",
            "Epoch 50/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.1951 - val_acc: 0.9444\n",
            "Epoch 51/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9444\n",
            "Epoch 52/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9444\n",
            "Epoch 53/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1910 - val_acc: 0.9444\n",
            "Epoch 54/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9444\n",
            "Epoch 55/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9444\n",
            "Epoch 56/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9444\n",
            "Epoch 57/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9444\n",
            "Epoch 58/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1994 - val_acc: 0.9444\n",
            "Epoch 59/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.2108 - val_acc: 0.9444\n",
            "Epoch 60/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1995 - val_acc: 0.9444\n",
            "Epoch 61/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1852 - val_acc: 0.9444\n",
            "Epoch 62/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1885 - val_acc: 0.9444\n",
            "Epoch 63/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9444\n",
            "Epoch 64/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9444\n",
            "Epoch 65/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9444\n",
            "Epoch 66/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9444\n",
            "Epoch 67/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2311 - val_acc: 0.9444\n",
            "Epoch 68/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 0.9444\n",
            "Epoch 69/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9444\n",
            "Epoch 70/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2212 - val_acc: 0.9444\n",
            "Epoch 71/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 0.9444\n",
            "Epoch 72/80\n",
            "36/36 [==============================] - 7s 186ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1956 - val_acc: 0.9444\n",
            "Epoch 73/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.9444\n",
            "Epoch 74/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2154 - val_acc: 0.9444\n",
            "Epoch 75/80\n",
            "36/36 [==============================] - 7s 184ms/step - loss: 9.9707e-04 - acc: 1.0000 - val_loss: 0.2119 - val_acc: 0.9444\n",
            "Epoch 76/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9444\n",
            "Epoch 77/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.2137 - val_acc: 0.9444\n",
            "Epoch 78/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 9.8067e-04 - acc: 1.0000 - val_loss: 0.1854 - val_acc: 0.9444\n",
            "Epoch 79/80\n",
            "36/36 [==============================] - 7s 185ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.9444\n",
            "Epoch 80/80\n",
            "36/36 [==============================] - 7s 186ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2271 - val_acc: 0.9444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NVj286xUVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_file_2 = drive.CreateFile()\n",
        "upload_file_2.SetContentFile(\"ape.hdf5\")\n",
        "upload_file_2.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}